"""
Stage 5: AI Semantic Scoring with GPT-4o-mini
- Pre-filtering uÅ¼ywajÄ…c acoustic + keyword scores
- Deep semantic analysis z GPT (tylko top 40)
- Composite scoring (acoustic + lexical + semantic)
"""

import json
from pathlib import Path
from typing import Dict, Any, List, Optional, Callable
import numpy as np
from scipy.special import expit as sigmoid
import os
from dotenv import load_dotenv

try:
    from openai import OpenAI
except ImportError:
    print("âš ï¸ openai nie zainstalowany. InstalujÄ™...")
    import subprocess
    subprocess.check_call(["pip", "install", "openai"])
    from openai import OpenAI

from .config import Config

# Load environment variables
load_dotenv()


class ScoringStage:
    """Stage 5: AI Semantic Scoring with GPT"""

    def __init__(self, config: Config):
        self.config = config
        self.openai_client = None
        self._load_gpt()

    def _get_system_prompt(self) -> str:
        """Get language-aware system prompt"""
        if self.config.language == "pl":
            return "JesteÅ› ekspertem od analizy politycznych debat i treÅ›ci viralowych."
        else:  # English
            return "You are an expert at analyzing live streams and viral content."

    def _get_scoring_prompt(self, transcripts_text: str, batch_size: int) -> str:
        """Get language-aware scoring prompt"""
        if self.config.language == "pl":
            return f"""OceÅ„ te fragmenty debaty sejmowej pod kÄ…tem INTERESANTOÅšCI dla widza YouTube (0.0-1.0):

{transcripts_text}

Kryteria WYSOKIEGO score (0.7-1.0):
- Ostra polemika, kÅ‚Ã³tnie, wymiana oskarÅ¼eÅ„
- Emocje, podniesiony gÅ‚os, sarkazm, ironia
- Kontrowersje, skandale, zaskakujÄ…ce stwierdzenia
- Momenty memiczne, Å›mieszne, absurdalne
- Przerwania, reakcje sali, oklaski/buczenie

Kryteria NISKIEGO score (0.0-0.3):
- Formalne procedury, regulaminy
- Monotonne odczytywanie list, liczb
- PodziÄ™kowania, grzecznoÅ›ci
- Nudne, techniczne szczegÃ³Å‚y

Odpowiedz TYLKO w formacie JSON:
{{"scores": [0.8, 0.3, 0.9, ...]}}

Tablica ma {batch_size} elementÃ³w - po jednym score dla kaÅ¼dego [N]."""
        else:  # English
            return f"""Rate these stream/video segments for INTERESTINGNESS for YouTube viewers (0.0-1.0):

{transcripts_text}

HIGH score criteria (0.7-1.0):
- Heated arguments, debates, confrontations
- Emotional moments, raised voice, sarcasm, irony
- Controversial, scandalous, surprising statements
- Meme-worthy, funny, absurd moments
- Interruptions, audience reactions, applause/booing
- Exciting gameplay moments, clutch plays, fails

LOW score criteria (0.0-0.3):
- Formal procedures, rules reading
- Monotonous listing, numbers, technical details
- Thank yous, pleasantries
- Boring, mundane content
- Dead air, silence, waiting

Reply ONLY in JSON format:
{{"scores": [0.8, 0.3, 0.9, ...]}}

Array must have {batch_size} elements - one score for each [N]."""
    
    def _load_gpt(self):
        """ZaÅ‚aduj GPT API"""
        api_key = os.getenv("OPENAI_API_KEY")
        
        if not api_key:
            print("âš ï¸ OPENAI_API_KEY nie znaleziony w .env")
            print("   UÅ¼ywam fallback (bez GPT scoring)")
            return
        
        try:
            self.openai_client = OpenAI(api_key=api_key)
            print("âœ“ GPT-4o-mini API zaÅ‚adowane")
        except Exception as e:
            print(f"âš ï¸ BÅ‚Ä…d Å‚adowania GPT: {e}")
            self.openai_client = None
    
    def process(
        self,
        segments: List[Dict],
        output_dir: Path,
        progress_callback: Optional[Callable] = None
    ) -> Dict[str, Any]:
        """
        GÅ‚Ã³wna metoda przetwarzania
        
        Returns:
            Dict zawierajÄ…cy segments z finalnym scoring
        """
        print(f"ðŸ§  AI Semantic Scoring dla {len(segments)} segmentÃ³w...")
        
        # STAGE 1: Pre-filtering (acoustic + keyword heuristics)
        print("ðŸ“Š Stage 1: Pre-filtering...")
        candidates = self._prefilter_candidates(segments)
        
        print(f"   âœ“ Wybrano {len(candidates)} kandydatÃ³w do AI eval")
        
        # STAGE 2: Deep semantic analysis (GPT)
        print("ðŸ¤– Stage 2: GPT Semantic Analysis...")
        if self.openai_client:
            candidates = self._semantic_analysis_gpt(
                candidates,
                progress_callback=progress_callback
            )
        else:
            print("   âš ï¸ GPT niedostÄ™pne, uÅ¼ywam fallback scoring")
            candidates = self._semantic_analysis_fallback(candidates)
        
        # STAGE 3: Final composite scoring
        print("âš–ï¸ Stage 3: Final Composite Scoring...")
        scored_segments = self._compute_final_scores(segments, candidates)
        
        # Sort by score
        scored_segments.sort(key=lambda x: x['final_score'], reverse=True)
        
        # Zapisz
        output_file = output_dir / "scored_segments.json"
        self._save_segments(scored_segments, output_file)
        
        # Stats
        avg_score = np.mean([s['final_score'] for s in scored_segments])
        print(f"   Åšredni score: {avg_score:.3f}")
        print(f"   Top score: {scored_segments[0]['final_score']:.3f}")
        
        print("âœ… Stage 5 zakoÅ„czony")
        
        return {
            'segments': scored_segments,
            'num_segments': len(scored_segments),
            'num_ai_evaluated': len(candidates),
            'output_file': str(output_file)
        }
    
    def _prefilter_candidates(self, segments: List[Dict]) -> List[Dict]:
        """Pre-filtering: wybierz top-N segmentÃ³w do GPT evaluation"""
        candidates = []
        
        for seg in segments:
            features = seg.get('features', {})
            
            # Acoustic score (normalized features)
            acoustic_score = (
                0.35 * features.get('rms_z', 0) +
                0.25 * features.get('spectral_centroid_z', 0) +
                0.20 * features.get('speech_rate_wpm', 0) / 200 +
                0.15 * features.get('spectral_flux', 0) +
                0.05 * features.get('dramatic_pauses', 0)
            )
            
            # Keyword boost
            keyword_score = features.get('keyword_score', 0)
            keyword_score_norm = min(keyword_score / 10, 1.0)
            
            # Pre-score
            pre_score = 0.6 * acoustic_score + 0.4 * keyword_score_norm
            seg['pre_score'] = float(pre_score)
            
            # Force include high keyword scores
            if keyword_score >= self.config.scoring.prefilter_keyword_threshold:
                candidates.append(seg)
        
        # Sort by pre_score
        segments_sorted = sorted(segments, key=lambda x: x.get('pre_score', 0), reverse=True)
        
        # Take top-N
        top_n = segments_sorted[:self.config.scoring.prefilter_top_n]
        
        # Merge with force-included (deduplicate)
        candidate_ids = {c['id'] for c in candidates}
        for seg in top_n:
            if seg['id'] not in candidate_ids:
                candidates.append(seg)
                candidate_ids.add(seg['id'])
        
        return candidates
    
    def _semantic_analysis_gpt(
        self,
        candidates: List[Dict],
        progress_callback: Optional[Callable] = None
    ) -> List[Dict]:
        """Deep semantic analysis uÅ¼ywajÄ…c GPT-4o-mini"""
        
        if not candidates:
            return []
        
        # Batch processing - 10 segmentÃ³w na raz
        batch_size = 10
        total = len(candidates)
        
        for batch_idx in range(0, total, batch_size):
            batch = candidates[batch_idx:batch_idx + batch_size]
            
            # Progress
            progress_pct = batch_idx / total
            if progress_callback:
                progress_callback(
                    progress_pct,
                    f"GPT eval batch {batch_idx//batch_size + 1}/{(total + batch_size - 1)//batch_size}"
                )
            
            # Przygotuj transkrypty
            transcripts_text = ""
            for i, seg in enumerate(batch):
                transcript = seg.get('transcript', '')[:400]  # Max 400 chars
                transcripts_text += f"\n[{i}] {transcript}\n"

            # Get language-aware prompts
            system_prompt = self._get_system_prompt()
            user_prompt = self._get_scoring_prompt(transcripts_text, len(batch))

            try:
                response = self.openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    response_format={"type": "json_object"},
                    max_tokens=200,
                    temperature=0.3
                )
                
                result = json.loads(response.choices[0].message.content)
                scores = result.get('scores', [])
                
                # Assign scores
                for i, seg in enumerate(batch):
                    if i < len(scores):
                        seg['semantic_score'] = float(min(max(scores[i], 0.0), 1.0))
                    else:
                        seg['semantic_score'] = 0.5
                
                print(f"   âœ“ Batch {batch_idx//batch_size + 1}: avg score {np.mean(scores):.2f}")
                
            except Exception as e:
                print(f"   âš ï¸ GPT batch {batch_idx//batch_size + 1} error: {e}")
                # Fallback to neutral scores
                for seg in batch:
                    seg['semantic_score'] = 0.5
        
        return candidates
    
    def _semantic_analysis_fallback(self, candidates: List[Dict]) -> List[Dict]:
        """Fallback scoring bez GPT (uÅ¼ywa tylko keywords)"""
        for seg in candidates:
            features = seg.get('features', {})
            keyword_score = features.get('keyword_score', 0)
            # Simple heuristic
            seg['semantic_score'] = min(keyword_score / 15.0, 1.0)
        
        return candidates
    
    def _compute_final_scores(
        self,
        all_segments: List[Dict],
        ai_evaluated: List[Dict]
    ) -> List[Dict]:
        """Oblicz finalne composite scores"""
        
        # Create lookup for AI evaluated segments
        ai_scores = {seg['id']: seg for seg in ai_evaluated}
        
        scored = []
        
        for seg in all_segments:
            seg_id = seg['id']
            features = seg.get('features', {})
            
            # Base scores
            acoustic_score = seg.get('pre_score', 0) * 0.6
            keyword_score = min(features.get('keyword_score', 0) / 10, 1.0)
            speaker_change = features.get('speaker_change_prob', 0.5)
            
            if seg_id in ai_scores:
                # Full formula z GPT
                semantic_score = ai_scores[seg_id].get('semantic_score', 0)
                
                final_score = (
                    self.config.scoring.weight_acoustic * acoustic_score +
                    self.config.scoring.weight_keyword * keyword_score +
                    self.config.scoring.weight_semantic * semantic_score +
                    self.config.scoring.weight_speaker_change * speaker_change
                )
                
                seg['semantic_score'] = semantic_score
                
            else:
                # Only heuristics (penalty)
                final_score = (acoustic_score + keyword_score) / 2 * 0.6
                seg['semantic_score'] = 0.0
            
            # Position diversity bonus
            position = features.get('position_in_video', 0.5)
            position_bonus = 1.0 + self.config.scoring.position_diversity_bonus * (1 - abs(position - 0.5))
            
            final_score *= position_bonus
            
            # Clamp to [0, 1]
            final_score = float(np.clip(final_score, 0, 1))
            
            seg['final_score'] = final_score
            seg['subscores'] = {
                'acoustic': float(acoustic_score),
                'keyword': float(keyword_score),
                'semantic': seg['semantic_score'],
                'speaker_change': float(speaker_change)
            }
            
            scored.append(seg)
        
        return scored
    
    def _save_segments(self, segments: List[Dict], output_file: Path):
        """Zapisz scored segments"""
        serializable = []
        for seg in segments:
            seg_copy = seg.copy()
            if 'final_score' in seg_copy:
                seg_copy['final_score'] = float(seg_copy['final_score'])
            serializable.append(seg_copy)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(serializable, f, indent=2, ensure_ascii=False)
        
        print(f"   ðŸ’¾ Scored segments zapisane: {output_file.name}")
    
    def cancel(self):
        """Anuluj operacjÄ™"""
        pass